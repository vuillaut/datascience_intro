{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands On Scipy Tutorial \n",
    "**Tutors:** Léa Jouvin\n",
    "\n",
    "This hands-on tutorial gives an introduction and overview of the [Scipy](http://www.scipy.org/) Python package and was done by Axel Donath that gave the [online course last year](https://escape2021.github.io/school2021/posts/clase15/). This course was based on the [excellent Scipy tutorial](https://github.com/Asterics2020-Obelics/School2019/blob/master/scipy/scipy_general.ipynb) by Maximilian Noethe and Kai Brügge from the past Asterics software summer school 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preface\n",
    "We recommend to follow this tutorial by **executing the code cells on your local machine**, along with the tutor. Every sub-topic we will cover in this tutorial will be concluded by a few **exercises** with different levels of difficulty** (*easy*, *advanced* and *hard*). The exercises will not be discussed during the course, however we provide a **sample solution** for all exercises in the **solutions folder** you can look at **after the course** and load them directly in the notebook. You can always ask for help on the exercises on the corresponding Slack channel **#d05-fri11-scipy**.   \n",
    "\n",
    "The estimated time for this tutorial is ~1.5 hours. We have marked some of the sections that deal with more advanced topics as \"optional\". \n",
    "\n",
    "We're happy to receive any **feedback or questions** on the tutorial via mail to *lea.jouvin@cea.fr* or using the \n",
    "repository's [issue tracker](https://github.com/escape2020/school2022/issues). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](scipy_logo.png)\n",
    "\n",
    "The SciPy framework builds on top of the low-level NumPy framework for multidimensional arrays, and provides a large number of higher-level scientific algorithms. Some of the topics that SciPy covers are:\n",
    "\n",
    "* Special functions ([scipy.special](http://docs.scipy.org/doc/scipy/reference/special.html))\n",
    "* Integration and ODE  ([scipy.integrate](http://docs.scipy.org/doc/scipy/reference/integrate.html))\n",
    "* Optimization ([scipy.optimize](http://docs.scipy.org/doc/scipy/reference/optimize.html))\n",
    "* Interpolation ([scipy.interpolate](http://docs.scipy.org/doc/scipy/reference/interpolate.html))\n",
    "* Fourier Transforms ([scipy.fftpack](http://docs.scipy.org/doc/scipy/reference/fftpack.html))\n",
    "* Signal Processing ([scipy.signal](http://docs.scipy.org/doc/scipy/reference/signal.html))\n",
    "* Linear Algebra ([scipy.linalg](http://docs.scipy.org/doc/scipy/reference/linalg.html))\n",
    "* Sparse Eigenvalue Problems ([scipy.sparse](http://docs.scipy.org/doc/scipy/reference/sparse.html))\n",
    "* Statistics ([scipy.stats](http://docs.scipy.org/doc/scipy/reference/stats.html))\n",
    "* Multi-dimensional image processing ([scipy.ndimage](http://docs.scipy.org/doc/scipy/reference/ndimage.html))\n",
    "* File IO ([scipy.io](http://docs.scipy.org/doc/scipy/reference/io.html))\n",
    "\n",
    "Each submodule in SciPy  provides a number of functions and classes that can be used to solve problems in their respective domain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:17:52.126028Z",
     "start_time": "2019-04-10T13:17:49.642680Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear algebra module contains a lot of matrix related functions, including linear equation solving, eigenvalue solvers, matrix functions (for example matrix-exponentiation), a number of different decompositions (SVD, LU, cholesky), etc. \n",
    "\n",
    "Detailed documetation is available at: http://docs.scipy.org/doc/scipy/reference/linalg.html\n",
    "\n",
    "Here we will look at how to use some of these functions:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Linear equation systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear equation systems on the matrix form\n",
    "\n",
    "$A x = b$\n",
    "\n",
    "where $A$ is a matrix and $x,b$ are vectors can be solved like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:17:52.207788Z",
     "start_time": "2019-04-10T13:17:52.175658Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:17:52.301861Z",
     "start_time": "2019-04-10T13:17:52.216850Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a matrix A of size 10*10 with random number\n",
    "A = (np.arange(100) + rng.normal(0, 10, size=(100))).reshape(10, 10)\n",
    "b = np.arange(10)\n",
    "A.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:17:52.857323Z",
     "start_time": "2019-04-10T13:17:52.317313Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.matshow(A)\n",
    "plt.grid(False) # turn off the grid for this plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:17:52.937662Z",
     "start_time": "2019-04-10T13:17:52.877962Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = linalg.solve(A, b)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:17:52.986299Z",
     "start_time": "2019-04-10T13:17:52.945971Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check whether we found the correct x. All entries should be close to zero.\n",
    "np.dot(A, x) - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To facilitate the check, we can use the methode allclose from numpy that will return True if all values are equal to 0 with a certain tolerance atol\n",
    "np.allclose(np.dot(A, x) - b, 0, atol=1e-14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do the same with\n",
    "\n",
    "$A X = B$\n",
    "\n",
    "where $A, B, X$ are matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:17:53.735550Z",
     "start_time": "2019-04-10T13:17:53.006639Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "A = rng.uniform(size=(5, 5))\n",
    "B = rng.uniform(size=(5, 5))\n",
    "f, [ax1, ax2] = plt.subplots(1, 2)\n",
    "ax1.matshow(A)\n",
    "ax2.matshow(B)\n",
    "ax1.grid(False)\n",
    "ax2.grid(False)\n",
    "ax1.set_title(\"Matrix A\")\n",
    "ax2.set_title(\"Matrix B\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:17:53.776446Z",
     "start_time": "2019-04-10T13:17:53.752204Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = linalg.solve(A, B)\n",
    "X\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:17:53.834916Z",
     "start_time": "2019-04-10T13:17:53.800756Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check\n",
    "np.allclose(linalg.norm(np.dot(A, X) - B), 0, atol=1e-14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Eigenvalues and eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eigenvalue problem for a matrix $A$ of size $m \\times m$:\n",
    "\n",
    "$\\displaystyle A v_n = \\lambda_n v_n$ $\\Longleftrightarrow$ $(A-\\lambda_n I_m) \\cdot v_n = 0$\n",
    "\n",
    "where $v_n$ is the $n$th eigenvector and $\\lambda_n$ is the $n$th eigenvalue. $I_m$ is the identity matrix of size m.\n",
    "\n",
    "\n",
    "To calculate eigenvalues of a matrix, use the `eigvals` and for calculating both eigenvalues and eigenvectors, use the function `eig`. Both return complex numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:17:53.870959Z",
     "start_time": "2019-04-10T13:17:53.846835Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "A = rng.uniform(size=(4, 4))\n",
    "\n",
    "eigen_values = linalg.eigvals(A)\n",
    "eigen_values\n",
    "print(f\"We get the {len(eigen_values)} associated eigens value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:17:53.909409Z",
     "start_time": "2019-04-10T13:17:53.878389Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "values, vectors = linalg.eig(A)\n",
    "values, vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The values are the Eigens values and the vectors are the 4 eigenvectors of shape 4 given in a 4*4 matrix\n",
    "print(values == eigen_values)\n",
    "print(vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the results. Here m=4\n",
    "I=np.identity(4)\n",
    "for i_n, lambda_n in enumerate(values):\n",
    "    is_eigenvalue=np.allclose(np.dot(A,vectors[:,i_n])-np.dot(lambda_n*I,vectors[:,i_n]), 0)\n",
    "    print(is_eigenvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also more specialized solvers, like the `eigh` for Hermitian matrices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Exercise:  Simple Linear Algebra\n",
    "\n",
    "1. Create a 10x10 matrix $A$ with random entries\n",
    "\n",
    "2. Create a symmetric matrix from $A$ using its transpose (use A.T to transpose) and then plot the new matrix using `plt.matshow`\n",
    "\n",
    "3. Use `linalg.eigh` to get the eigenvalues and vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:17:53.932739Z",
     "start_time": "2019-04-10T13:17:53.920340Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load solutions/simple_linalg_solution.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Special Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A large number of mathematical special functions are important for many computional physics problems. SciPy provides implementations of a very extensive set of special functions. For details, see the list of functions in the reference documention at http://docs.scipy.org/doc/scipy/reference/special.html#module-scipy.special. \n",
    "\n",
    "- Airy functions\n",
    "- Elliptic functions and integrals\n",
    "- Bessel functions\n",
    "- Gamma functions\n",
    "- etc...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Polynomials\n",
    "\n",
    "The module contains a large number of functions for evaluating polynomials and calculating their roots.\n",
    "\n",
    "The following plot shows just a few of them at different orders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:17:57.512706Z",
     "start_time": "2019-04-10T13:17:56.067256Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy import special\n",
    "\n",
    "functions = {\n",
    "    \"Chebyshev\": special.eval_chebys,\n",
    "    \"Laguerre\": special.eval_laguerre,\n",
    "    \"Legendre\": special.eval_legendre,\n",
    "    \"Chebyshev II\": special.eval_chebyu\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, sharex=True, sharey=True, figsize=(12, 8))\n",
    "\n",
    "x = np.linspace(-2., 2., 200)\n",
    "\n",
    "for name, ax in zip(functions, axes.flat):\n",
    "    f = functions[name]\n",
    "    # iterative loop on the order\n",
    "    for n in range(5):\n",
    "        ax.plot(x, f(n, x), label=f\"Order {n}\")\n",
    "    \n",
    "    ax.set_title(name)\n",
    "    ax.set_ylim([-3, 3])\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Statistical Functions\n",
    "\n",
    "The module also contains a host of useful functions for statistical computations. for example the so called 'error function' `scipy.special.erf`\n",
    "\n",
    "\\begin{align}\n",
    "\\operatorname {erf}(x)&={\\frac {1}{\\sqrt {\\pi }}}\\int _{-x}^{x}e^{-t^{2}},dt \\\\ &={\\frac {2}{\\sqrt {\\pi }}}\\int _{0}^{x}e^{-t^{2}}\\,dt.\n",
    "\\end{align}\n",
    "\n",
    "Which allows you to get the cumulative of the unit normal distribution:\n",
    "$$\n",
    "\\phi(z) = \\frac 1 2 \\left(1 + erf\\left(\\frac{z}{sqrt(2)}\\right) \\right)\n",
    "$$\n",
    "\n",
    "The module `scipy.stats` contains nicer methods to handle statistical methods. More on that later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:17:59.040290Z",
     "start_time": "2019-04-10T13:17:57.527868Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-3, 3)\n",
    "plt.plot(x, special.erf(x), label='$erf$')\n",
    "plt.plot(x, 0.5 * (1 + special.erf(x / np.sqrt(2))), label='$phi$')\n",
    "plt.xlabel('$x$')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Bessel Functions\n",
    "To demonstrate the typical usage of special functions we will look in more detail at the Bessel functions.\n",
    "\n",
    "Bessel functions are a family of solutions to Bessel’s differential equation with real or complex order alpha:\n",
    "$$\n",
    "x^2 \\frac{d^2 y}{dx^2} +x  \\frac{dy}{dx} +(x^2−α^2)y=0\n",
    "$$\n",
    "\n",
    " Bessel functions are especially important for many problems of wave propagation and static potential in cylindric or spherical coordinates.\n",
    " \n",
    "The `scipy.special` module includes a large number of Bessel-functions\n",
    "Here we will use the functions $j_n$ and $y_n$, which are the Bessel functions \n",
    "of the first and second kind and real-valued order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:17:59.994833Z",
     "start_time": "2019-04-10T13:17:59.051434Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy import special\n",
    "\n",
    "x = np.linspace(0, 10, 100)\n",
    "\n",
    "for n in range(4):\n",
    "    plt.plot(x, special.jn(n, x), label=f'$J_{n}(x)$')\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among other uses, these functions arise in wave propagation problems such as the vibrational modes of a thin drum head. Here is an example of a circular drum head anchored at the edge. See https://en.wikipedia.org/wiki/Vibrations_of_a_circular_membrane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:00.069827Z",
     "start_time": "2019-04-10T13:18:00.009579Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fix the radius of the drum\n",
    "DRUM_RADIUS = 1\n",
    "\n",
    "def drumhead_height(n, k, radius, theta, t):\n",
    "    '''Solution to the Drumhead problem with a fixed membrane on the edge of the drum\n",
    "    See https://en.wikipedia.org/wiki/Vibrations_of_a_circular_membrane\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n : radial eigen mode\n",
    "    k : spherical eigen mode\n",
    "    radius: radius from the center of the membrane\n",
    "    theta: spherical angle \n",
    "    t: time\n",
    "    '''\n",
    "    kth_zero = special.jn_zeros(n, k)[-1] # fix the drum on the outter edge to be zero.\n",
    "    return np.cos(t) * np.cos(n * theta) * special.jn(n, radius * kth_zero / DRUM_RADIUS)\n",
    "\n",
    "\n",
    "# create two coordinate vectors containing all combinations of radius and theta we want to plot\n",
    "r = np.linspace(0, DRUM_RADIUS, 50)\n",
    "th = np.linspace(0, 2 * np.pi, 50)\n",
    "radius, theta = np.meshgrid(r, th) # this creates all combinations we are interested in\n",
    "\n",
    "#Carthesian coordinates\n",
    "x = radius * np.cos(theta)\n",
    "y = radius * np.sin(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:01.770589Z",
     "start_time": "2019-04-10T13:18:00.095294Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "idx = 1\n",
    "\n",
    "# Iterative lool on the radial eigen mode and spherical eigen mode for a fixe time t=0.5\n",
    "for n in range(3):\n",
    "    for k in range(1, 4):\n",
    "        ax = fig.add_subplot(3, 3, idx, projection='3d')\n",
    "        z = drumhead_height(n=n, k=k, radius=radius, theta=theta, t=0.5)\n",
    "        ax.plot_surface(x, y, z, cmap='YlGnBu')\n",
    "        ax.set_title(f\"n={n}, k={k}\", fontsize=14)\n",
    "        ax.axis('off')\n",
    "        idx += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `scripts` folder you find an example script that creates the following animation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:01.837451Z",
     "start_time": "2019-04-10T13:18:01.815673Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Animation made from the script drum_head_animation.py in script for differetn time and eigen radial mode of 2 \n",
    "# and eigen spherical mode of 1 \n",
    "from IPython.display import Video\n",
    "Video('scripts/animation_membrane.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ordinary Differential Equations\n",
    "\n",
    "### 3.1 Zombie outbreak\n",
    "\n",
    "To demonstrate the usefulness of SciPy lets try to predict what will happen to humanity in case of a zombie outbreak.  This example comes courtesy of Christopher Campo.\n",
    "\n",
    "We will show that, in case of a Zombie outbreak, humanity is inevitably doomed. \n",
    "As shown by [Phillip Munz et al](http://mysite.science.uottawa.ca/rsmith43/Zombies.pdf) we can model a simple outbreak scenario like so.\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{S}{dt} &= B - \\beta S Z - \\delta S \\\\\n",
    "\\frac{Z}{dt} &= \\beta S Z + \\gamma R - \\alpha S Z \\\\\n",
    "\\frac{R}{dt} &= \\delta S + \\alpha S Z - \\gamma R\n",
    "\\end{align}\n",
    "\n",
    "Where $S$ is the number of susceptible humans, $Z$ is the number of zombies and $R$ is the number of removed persons which have died either by natural causes or zombie attack. The human birthrate is assumed to be constant and modeled by $B$\n",
    "\n",
    "Susceptibles can become zombies through an encounter with a zombie ($\\beta$). Natural causes of human deaths are parameterized by $\\delta$. Humans in the removed class can be resurrected and become zombies ($\\gamma$).  \n",
    "Zombies can enter the removed class by cutting their heads of or removing their brains ($\\alpha$)\n",
    "\n",
    "The question I'm trying to answer is \n",
    "\n",
    "> __Can Humanity survive the zombie Apocalypse?__\n",
    "\n",
    "Since I don't know how to solve differential equations, I'm going to use SciPy instead.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use SciPy to solve this system of differential equations. The function `solve_ivp` does the entire job for us. \n",
    "\n",
    "If we go to [the SciPy documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.solve_ivp.html#scipy.integrate.solve_ivp) about this function we will read the following.\n",
    "\n",
    "\n",
    ">This function numerically integrates a system of ordinary differential equations given an initial value:\n",
    ">\n",
    "> $y^{\\prime} = f(t, y)$\n",
    ">\n",
    ">$y(t_0) = y_0$\n",
    ">\n",
    ">Here $t$ is a one-dimensional independent variable (time), $y(t)$ is an __n-dimensional vector-valued function__ (state), and an __n-dimensional vector-valued function f(t, y) determines the differential equations__. The goal is to find y(t) approximately satisfying the differential equations, given an initial value y(t0)=y0.\n",
    "\n",
    "\n",
    "So we start by defining some starting values for the problem and the model function $f(t, y)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:01.893983Z",
     "start_time": "2019-04-10T13:18:01.847416Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "# Type `solve_ivp?` to get inline documentation about the method in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:02.052831Z",
     "start_time": "2019-04-10T13:18:01.906264Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fixed model parameters\n",
    "B = 0.1 # birth rate\n",
    "delta = 0.0001 # rate of natural causes of death\n",
    "beta = 0.00016 # transmission coefficent\n",
    "gamma = 0.0001 # resurrection rate\n",
    "alpha = 0.0001 # rate of destroyed zombies\n",
    "\n",
    "# initial conditions\n",
    "S0 = 5000.              # initial population\n",
    "Z0 = 0                 # initial zombie population\n",
    "R0 = 0                 # initial dead population\n",
    "y0 = [S0, Z0, R0]     # initial condition vector\n",
    "\n",
    "# f_model function that has to be given in a form required by scipy,\n",
    "# f taking the time and the state y parameter and then returning the corresponding differential.\n",
    "def f_model(t, y):\n",
    "    Si, Zi, Ri = y\n",
    "\n",
    "    # the model equations (see Munz et al. 2009)\n",
    "    f0 = B - beta * Si * Zi - delta * Si\n",
    "    f1 = beta * Si * Zi + gamma * Ri - alpha * Si * Zi\n",
    "    f2 = delta * Si + alpha * Si * Zi - gamma * Ri\n",
    "    return [f0, f1, f2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we solve the equation and output the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:02.153545Z",
     "start_time": "2019-04-10T13:18:02.057735Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t_start, t_end = 0, 200  # 200 days of zombie apocalypse\n",
    "solution = solve_ivp(f_model, (t_start, t_end), y0, t_eval=np.linspace(t_start, t_end, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return an OdeResult with useful property on the resolution, in partiular if the fits does'nt converge.\n",
    "print(type(solution))\n",
    "print(solution.message)\n",
    "print(solution.success)\n",
    "print(solution.nfev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solutions of the problem are return in solution.y: Number of rates (3 here) * Number of steps (fix to 200)\n",
    "print(solution.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:02.936104Z",
     "start_time": "2019-04-10T13:18:02.165130Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Number of survivor with time\n",
    "s = solution.y[0, :]\n",
    "# Number of zombies with time\n",
    "z = solution.y[1, :]\n",
    "plt.plot(solution.t, s, label='survivors')\n",
    "plt.plot(solution.t, z, label='zombies')\n",
    "plt.xlabel('t / days')\n",
    "plt.ylabel('Population')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Exercise: Save the world.\n",
    "\n",
    "The ODE defined above is a very pessimistic model. There is one unstable equilibrium state if $\\beta = 0$.\n",
    "Your task is to save the world by adding a the notion of a _cure_ to the model above. The cure \n",
    "can move individuals from the $Z$ to the $S$ group.\n",
    "\n",
    "1. Introduce a new constant $\\rho$ which models the effectivness of the cure. \n",
    "2. Add a term to the ODE to model the cure. \n",
    "3. Solve the ODE using `solve_ivp`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:02.970236Z",
     "start_time": "2019-04-10T13:18:02.955813Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load solutions/solution_zombies.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 A complex ODE\n",
    "A more complex case of coupled differential equations for a double pendule is given again in the `scripts` folder, which creates the following animation.\n",
    "\n",
    "It uses `solve_ivp` method to numerically solve the following system of coupled differential euqations :\n",
    "\n",
    "\\begin{aligned}{{\\dot {\\theta }}_{1}}&={\\frac {6}{ml^{2}}}{\\frac {2p_{\\theta _{1}}-3\\cos(\\theta _{1}-\\theta _{2})p_{\\theta _{2}}}{16-9\\cos ^{2}(\\theta _{1}-\\theta _{2})}}\\\\{{\\dot {\\theta }}_{2}}&={\\frac {6}{ml^{2}}}{\\frac {8p_{\\theta _{2}}-3\\cos(\\theta _{1}-\\theta _{2})p_{\\theta _{1}}}{16-9\\cos ^{2}(\\theta _{1}-\\theta _{2})}}.\n",
    "\\end{aligned}\n",
    "\n",
    "\\begin{aligned}{{\\dot {p}}_{\\theta _{1}}}&={\\frac {\\partial L}{\\partial \\theta _{1}}}=-{\\tfrac {1}{2}}ml^{2}\\left({{\\dot {\\theta }}_{1}}{{\\dot {\\theta }}_{2}}\\sin(\\theta _{1}-\\theta _{2})+3{\\frac {g}{l}}\\sin \\theta _{1}\\right)\\\\{{\\dot {p}}_{\\theta _{2}}}&={\\frac {\\partial L}{\\partial \\theta _{2}}}=-{\\tfrac {1}{2}}ml^{2}\\left(-{{\\dot {\\theta }}_{1}}{{\\dot {\\theta }}_{2}}\\sin(\\theta _{1}-\\theta _{2})+{\\frac {g}{l}}\\sin \\theta _{2}\\right).\n",
    "\\end{aligned} \n",
    "\n",
    "The plot shows the results in carthesian coordinates $(x_1(t), y_1(t))$ and $(x_2(t), y_2(t))$ for the pendule 1 and 2, depending on the angles $\\theta_1(t)$ and $\\theta_2(t)$ as the following:\n",
    "\n",
    "\\begin{align}\n",
    "x_1(t) &= L \\; sin(\\theta_1(t))\\\\\n",
    "y_1(t) &= - L\\;  cos(\\theta_1(t)) \\\\\n",
    "x_2(t) &= x_1 + L \\; sin(\\theta_2(t)) \\\\\n",
    "y_2(t) &= y_1 - L \\; cos(\\theta_2(t))\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load scripts/double_pendulum_animation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:04.068682Z",
     "start_time": "2019-04-10T13:18:04.043483Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Video(\"scripts/animation_pendulum.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Numerical Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Quadrature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical evaluation of a function of the type\n",
    "\n",
    "$\\displaystyle \\int_a^b f(x) dx$\n",
    "\n",
    "is called *numerical quadrature*, or simply *quadature*. SciPy provides a series of functions for different kind of quadrature, for example the `quad`, `dblquad` and `tplquad` for single, double and triple integrals, respectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:04.147016Z",
     "start_time": "2019-04-10T13:18:04.135466Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.integrate import quad, dblquad, tplquad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `quad` function takes a large number of optional arguments, which can be used to fine-tune the behaviour of the function.\n",
    "\n",
    "The basic usage is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:04.166783Z",
     "start_time": "2019-04-10T13:18:04.156240Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# define a simple function for the integrand\n",
    "def f(x):\n",
    "    return x ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:04.986269Z",
     "start_time": "2019-04-10T13:18:04.176201Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_lower = 0 # the lower limit of x\n",
    "x_upper = 1 # the upper limit of x\n",
    "\n",
    "val, abserr = quad(func=f, a=x_lower, b=x_upper)\n",
    "\n",
    "print(f'integral value={val} , absolute error={abserr}' )\n",
    "\n",
    "x = np.linspace(-1.2, 1.2, 200)\n",
    "plt.plot(x, f(x))\n",
    "plt.fill_between(x, f(x), alpha=0.3, where=(x > 0) & (x < 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we need to pass extra arguments to integrand function we can use the `args` keyword argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:05.063781Z",
     "start_time": "2019-04-10T13:18:05.003320Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def integrand(x, n):\n",
    "    return special.jn(n, x)\n",
    "\n",
    "x_lower = 0  # the lower limit of x\n",
    "x_upper = 10 # the upper limit of x\n",
    "\n",
    "val, abserr = quad(integrand, x_lower, x_upper, args=(3,))\n",
    "print(val, abserr) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simple functions we can use a lambda function (name-less function) instead of explicitly defining a function for the integrand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:05.101458Z",
     "start_time": "2019-04-10T13:18:05.078394Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val, abserr = quad(lambda x: np.exp(-x ** 2), -np.Inf, np.Inf)\n",
    "print(f'numerical= {val}, {abserr}')\n",
    "print(f'analytical solution = {np.sqrt(np.pi)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As show in the example above, we can also use 'Inf' or '-Inf' as integral limits.\n",
    "\n",
    "Higher-dimensional integration works in the same way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:07.444111Z",
     "start_time": "2019-04-10T13:18:05.114836Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def integrand(x, y):\n",
    "    return np.exp(-x**2 - y**2)\n",
    "\n",
    "\n",
    "x, y = np.meshgrid(np.linspace(-2, 2, 100), np.linspace(-2, 2, 100))\n",
    "z = integrand(x, y)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "ax.plot_surface(x, y, z, cmap='YlGnBu')\n",
    "\n",
    "# the integral boundarys can be functions when integrating in more than one dimensions\n",
    "val, abserr = dblquad(integrand, -2, 2, lambda x: -2, lambda x: 2) \n",
    "#val, abserr = dblquad(integrand, -2, 2, -2, 2) \n",
    "\n",
    "print(f'numerical solution= {val}, {abserr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we had to pass lambda functions for the limits for the y integration, since these in general can be functions of x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Exercise II:  Integrals and Special Functions\n",
    "\n",
    "Find the circumference of an ellipse. The formula for calculating circumference $C$ is as follows.\n",
    "\n",
    "$$\n",
    "\\frac{C}{4a} =  E(\\epsilon)=\\int _{0}^{\\pi /2}{\\sqrt {1-\\epsilon^{2}\\sin ^{2}\\theta }}\\ d\\theta\n",
    "$$\n",
    "\n",
    "where $\\epsilon$ is the eccentricity of the ellipse given by the length and width of the ellipse.\n",
    "\n",
    "$$\n",
    "\\epsilon = \\sqrt{1 - \\frac{b^2}{a^2}}\n",
    "$$\n",
    "\n",
    "compare the solution found using `quad` with the appropriate function from the `scipy.special` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:07.468798Z",
     "start_time": "2019-04-10T13:18:07.447622Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load solutions/solution_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Signal Processing\n",
    "\n",
    "SciPy offers a large amount of utilities to handle time series data. However the methods in the `scipy.signal` are useful for much more than just time series data.\n",
    "\n",
    "### 5.1 Convolution\n",
    "\n",
    "The convolution of two continuos functions is defined by a simple integral transform.\n",
    "\n",
    "\\begin{aligned}\n",
    "(f*g)(t)&\\,{\\stackrel {\\mathrm {def} }{=}}\\ \\int _{-\\infty }^{\\infty }f(\\tau )g(t-\\tau )\\,d\\tau \\\\&=\\int _{-\\infty }^{\\infty }f(t-\\tau )g(\\tau )\\,d\\tau .\n",
    "\\end{aligned}\n",
    "\n",
    "Convolution happens whenever data gets smeared out by a detector or filter of any kind.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:07.583301Z",
     "start_time": "2019-04-10T13:18:07.479099Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "# create two rectangular signals\n",
    "# first initial signal\n",
    "f = np.repeat([0., 1., 0.], 120)\n",
    "# filter impulse response\n",
    "g = np.repeat([0., 1., 0.], 20)\n",
    "\n",
    "result = signal.convolve(f, g, mode=\"same\")  # same output shape as input, see docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:08.634199Z",
     "start_time": "2019-04-10T13:18:07.588221Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, (ax_orig, ax_win, ax_filt) = plt.subplots(3, 1, sharex=True, figsize=(6, 6))\n",
    "\n",
    "ax_orig.plot(f, color='gray')\n",
    "ax_orig.set_title('Original pulse')\n",
    "ax_orig.margins(0, 0.1)\n",
    "\n",
    "ax_win.plot(g, color='gray')\n",
    "ax_win.arrow(70, 0.5, 50.0, 0.0, width=0.08, head_length=8)\n",
    "ax_win.set_title('Filter impulse response')\n",
    "\n",
    "#convolve signal where we get the ramps as expected by the modulation of the filter\n",
    "ax_filt.plot(result)\n",
    "ax_filt.set_title('Filtered signal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The naive algorithm for producing discrete convolutions is not very efficient. It takes $\\mathcal{O}(n^2)$ steps to get a result. A more efficient implementation is the FFT based alogrithm. It is based on the *convolution theorem*\n",
    "\n",
    "> The convolution theorem states that\n",
    ">\n",
    " $$\n",
    " \\mathcal{F}\\{f*g\\}=k\\cdot {\\mathcal {F}}\\{f\\}\\cdot {\\mathcal {F}}\\{g\\}\n",
    " $$\n",
    ">\n",
    "> where \n",
    "> $\\mathcal {F}\\{f\\}$ denotes the Fourier transform of $f$, and $\\mathcal {F}\\{g\\}$ the Fourier transform of $g$.\n",
    ">\n",
    "> https://en.wikipedia.org/wiki/Convolution\n",
    "\n",
    "A convolution can be describe as a multiplication in the fourrier space.\n",
    "\n",
    "SciPy uses a heuristic to automagically find the [fastest convolution method](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.choose_conv_method.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Signal Windows\n",
    "\n",
    "SciPy conveniently provides a handful of common signal windows ready to be used for convolution or other filtering operations. All of them can be found in `scipy.signal.window` but their are also available in the `scipy.signal` name space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:09.259874Z",
     "start_time": "2019-04-10T13:18:08.646101Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "windows = {\n",
    "    \"Nutall\": signal.nuttall(150),\n",
    "    \"Hannings\": signal.hann(150),\n",
    "    \"Cosine\": signal.cosine(150),\n",
    "    \"Triangle\": signal.triang(150),\n",
    "    \"Blackman\": signal.blackman(150)\n",
    "}\n",
    "\n",
    "for name, window in windows.items():\n",
    "    plt.plot(window, label=name)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Correlation\n",
    "\n",
    "The correlation of two functions $f$ and $g$ looks similar to a convolution \n",
    "\n",
    "> For continuous functions $f$ and $g$, the cross-correlation is defined as:\n",
    "> \n",
    "$$\n",
    "(f\\star g)(\\tau )\\ {\\stackrel {\\mathrm {def} }{=}}\\int _{-\\infty }^{\\infty }f^{*}(t)\\ g(t+\\tau )\\,dt,\n",
    "$$\n",
    "> \n",
    "> where $f^{*}$ denotes the complex conjugate of  $f$, and $\\tau$ is the displacement, also known as lag, although a positive value of $\\tau$ actually means that $g(t+\\tau)$ leads $f(t)$.\n",
    "\n",
    "> *https://en.wikipedia.org/wiki/Cross-correlation*\n",
    "\n",
    "\n",
    "The result of the correlation is a function of the delay $\\tau$. This is useful to cross match 2 different signals and to find the offset in shifted signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:09.312327Z",
     "start_time": "2019-04-10T13:18:09.278969Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "offset = 0.25\n",
    "t = np.linspace(-1, 1, 600)\n",
    "# Gaussian modulated sinusoid\n",
    "f = signal.gausspulse(t, fc=3)\n",
    "# Second sinal offset from the frist one by 0.25\n",
    "g = signal.gausspulse( t + offset, fc=3)\n",
    "\n",
    "# with the correlate method, we shift one signal over the other\n",
    "result = signal.correlate(f, g, mode='same')\n",
    "\n",
    "# we look for the place where the strongest correlation occurs\n",
    "offset = t[np.argmax(result)]\n",
    "offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is only as precise as the sampling we use for t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:10.298999Z",
     "start_time": "2019-04-10T13:18:09.326862Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid = plt.GridSpec(2, 2, wspace=0.1, hspace=0.4, width_ratios=[1, 1])\n",
    "ax1 = plt.subplot(grid[0, 0])\n",
    "ax2 = plt.subplot(grid[1, 0])\n",
    "ax3 = plt.subplot(grid[:, 1], )\n",
    "\n",
    "ax1.plot(t, f, color='gray')\n",
    "ax1.set_title('$f$')\n",
    "ax1.set_yticks([])\n",
    "ax1.set_xlabel('t')\n",
    "\n",
    "ax2.plot(t, g, color='gray')\n",
    "ax2.set_title('$g$')\n",
    "ax2.set_yticks([])\n",
    "ax2.set_xlabel('t')\n",
    "\n",
    "\n",
    "ax3.plot(t, result)\n",
    "ax3.axvline(offset, color='xkcd:tangerine')\n",
    "ax3.set_title('$(f\\star g)(\\\\tau )$')\n",
    "ax3.set_yticks([])\n",
    "ax3.set_xlabel('τ');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Exercise III:  Signal Filtering\n",
    "\n",
    "If we ever find an alien civilization we will have to communicate with them using binary encoded signals recorded by large radio telescopes.\n",
    "\n",
    "\n",
    "Assuming the aliens use binary signals with 0s and 1s. \n",
    "Given the clock speed and the sample length with which the signal was created. Can you decode the following signal?\n",
    "\n",
    "The plot below shows the shape of an example signal without any noise containing the message [0, 1 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:11.038589Z",
     "start_time": "2019-04-10T13:18:10.314893Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample_length = 64\n",
    "plt.plot(np.repeat([0, 1, 0], sample_length))\n",
    "plt.text(25, 0.5, '0')\n",
    "plt.text(100, 0.5, '1')\n",
    "plt.text(175, 0.5, '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:12.073432Z",
     "start_time": "2019-04-10T13:18:11.058235Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alien_signal = np.loadtxt('data/alien_signal.txt')\n",
    "sample_length = 128\n",
    "\n",
    "# let's sample the signal in the middle of each period\n",
    "clock = np.arange(sample_length // 2, len(alien_signal), sample_length)\n",
    "plt.plot(alien_signal)\n",
    "\n",
    "for c in clock:\n",
    "    plt.axvline(c, color='gray', lw=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:12.099455Z",
     "start_time": "2019-04-10T13:18:12.085376Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load solutions/solution_3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Fourier transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fourrier transform is not only usefull in the context of the convolution. You can be just interested in the Fourrier transform of a certain signal as the spectrum of a signal for example.\n",
    "\n",
    "Fourier transforms are one of the universal tools in computational physics, which appear over and over again in different contexts. SciPy provides functions for accessing the classic [FFTPACK](http://www.netlib.org/fftpack/) library, which is an efficient and well tested FFT library written in FORTRAN. The SciPy API has a few additional convenience functions, but overall the API is closely related to the original FORTRAN library.\n",
    "\n",
    "To use the `fft` module in a python program (known as fftpack before):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:12.142444Z",
     "start_time": "2019-04-10T13:18:12.107646Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy import fft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate how to do a fast Fourier transform with SciPy, we will create some artificial data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:13.122014Z",
     "start_time": "2019-04-10T13:18:12.146181Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sample points\n",
    "n_samples = 1000\n",
    "length = 10\n",
    "sample_size = length / n_samples\n",
    "\n",
    "# Define the space for the sampling\n",
    "x = np.linspace(0.0, length, n_samples)\n",
    "\n",
    "freqs = [8, 3, 32]\n",
    "amps = [1, 0.5, 0.25]\n",
    "\n",
    "# Artificial signal composed of different harmonic (different frequencies weighted by different amplitude)\n",
    "y = np.zeros(n_samples)\n",
    "for a, f in zip(amps, freqs):\n",
    "    y += a * np.sin(2 * np.pi * f * x)\n",
    "\n",
    "# We add some noise using a normal distribution\n",
    "y += rng.normal(0, 0.75, len(y))\n",
    "plt.plot(x, y, lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:13.919352Z",
     "start_time": "2019-04-10T13:18:13.134458Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# signal in the fourrier space here the frequency space\n",
    "yf = fft.fft(y)\n",
    "# Discrete Fourier Transform sample frequencies\n",
    "xf = fft.fftfreq(n_samples, sample_size)\n",
    "plt.plot(xf, np.abs(yf))\n",
    "plt.xlim(0, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we now see a peaks in the spectrum that match the true frequencies in the signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `scipy.stats` module contains a large number of statistical distributions, statistical functions and tests. For a complete documentation of its features, see http://docs.scipy.org/doc/scipy/reference/stats.html.\n",
    "\n",
    "Below we instantiate an object modeling a random variable following the normal distribution.\n",
    "\n",
    "### 6.1 Continuous Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:13.973763Z",
     "start_time": "2019-04-10T13:18:13.950784Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "mean = 0\n",
    "sigma = 1\n",
    "# Normal distribution\n",
    "X = stats.norm(loc=mean, scale=sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T14:46:47.298461Z",
     "start_time": "2018-06-02T14:46:47.287124Z"
    }
   },
   "source": [
    "All distributions in this submodule extend either `scipy.stats.rv_continuous` or `scipy.stats.rv_discrete`.\n",
    "Below is a list of functions supported by most continuous distribution objects\n",
    "\n",
    "```\n",
    "rvs(*args, **kwds) \tRandom variates of given type.\n",
    "pdf(x, *args, **kwds) \tProbability density function at x of the given RV.\n",
    "logpdf(x, *args, **kwds) \tLog of the probability density function at x of the given RV.\n",
    "cdf(x, *args, **kwds) \tCumulative distribution function of the given RV.\n",
    "logcdf(x, *args, **kwds) \tLog of the cumulative distribution function at x of the given RV.\n",
    "sf(x, *args, **kwds) \tSurvival function (1 - cdf) at x of the given RV.\n",
    "logsf(x, *args, **kwds) \tLog of the survival function of the given RV.\n",
    "ppf(q, *args, **kwds) \tPercent point function (inverse of cdf) at q of the given RV.\n",
    "isf(q, *args, **kwds) \tInverse survival function (inverse of sf) at q of the given RV.\n",
    "moment(n, *args, **kwds) \tn-th order non-central moment of distribution.\n",
    "stats(*args, **kwds) \tSome statistics of the given RV.\n",
    "entropy(*args, **kwds) \tDifferential entropy of the RV.\n",
    "expect([func, args, loc, scale, lb, ub, …]) \tCalculate expected value of a function with respect to the distribution.\n",
    "median(*args, **kwds) \tMedian of the distribution.\n",
    "mean(*args, **kwds) \tMean of the distribution.\n",
    "std(*args, **kwds) \tStandard deviation of the distribution.\n",
    "var(*args, **kwds) \tVariance of the distribution.\n",
    "interval(alpha, *args, **kwds) \tConfidence interval with equal areas around the median.\n",
    "__call__(*args, **kwds) \tFreeze the distribution for the given arguments.\n",
    "fit(data, *args, **kwds) \tReturn MLEs for shape (if applicable), location, and scale parameters from data.\n",
    "fit_loc_scale(data, *args) \tEstimate loc and scale parameters from data using 1st and 2nd moments.\n",
    "nnlf(theta, x) \tReturn negative loglikelihood function.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:15.699907Z",
     "start_time": "2019-04-10T13:18:13.984454Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N = 1200\n",
    "# Draw sample of size N from a probablity distribution, here the normal one.\n",
    "measurements = X.rvs(size=N)\n",
    "x = np.linspace(-3.5, 3.5, 200)\n",
    "\n",
    "f, [ax1, ax2] = plt.subplots(1, 2, figsize=(12, 5))\n",
    "ax1.hist(measurements, bins=40, density=True)\n",
    "ax1.plot(x, X.pdf(x), color='red')\n",
    "\n",
    "\n",
    "ax2.hist(measurements, bins=40, cumulative=True, density=True)\n",
    "ax2.plot(x, X.cdf(x), color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Discrete Distributions\n",
    "\n",
    "Discrete functions work in a very similar manner.\n",
    "\n",
    "\n",
    "```\n",
    "rvs(*args, **kwargs) \tRandom variates of given type.\n",
    "pmf(k, *args, **kwds) \tProbability mass function at k of the given RV.\n",
    "logpmf(k, *args, **kwds) \tLog of the probability mass function at k of the given RV.\n",
    "cdf(k, *args, **kwds) \tCumulative distribution function of the given RV.\n",
    "logcdf(k, *args, **kwds) \tLog of the cumulative distribution function at k of the given RV.\n",
    "sf(k, *args, **kwds) \tSurvival function (1 - cdf) at k of the given RV.\n",
    "logsf(k, *args, **kwds) \tLog of the survival function of the given RV.\n",
    "ppf(q, *args, **kwds) \tPercent point function (inverse of cdf) at q of the given RV.\n",
    "isf(q, *args, **kwds) \tInverse survival function (inverse of sf) at q of the given RV.\n",
    "moment(n, *args, **kwds) \tn-th order non-central moment of distribution.\n",
    "stats(*args, **kwds) \tSome statistics of the given RV.\n",
    "entropy(*args, **kwds) \tDifferential entropy of the RV.\n",
    "expect([func, args, loc, lb, ub, …]) \tCalculate expected value of a function with respect to the distribution for discrete distribution.\n",
    "median(*args, **kwds) \tMedian of the distribution.\n",
    "mean(*args, **kwds) \tMean of the distribution.\n",
    "std(*args, **kwds) \tStandard deviation of the distribution.\n",
    "var(*args, **kwds) \tVariance of the distribution.\n",
    "interval(alpha, *args, **kwds) \tConfidence interval with equal areas around the median.\n",
    "__call__(*args, **kwds) \tFreeze the distribution for the given arguments.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:15.754666Z",
     "start_time": "2019-04-10T13:18:15.729704Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create a (discreet) random variable with poissionian distribution\n",
    "Y = stats.poisson(3.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:16.738790Z",
     "start_time": "2019-04-10T13:18:15.777953Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = np.arange(0, 12)\n",
    "\n",
    "fig, axes = plt.subplots(3,1, sharex=True, figsize=(8, 8))\n",
    "\n",
    "# plot the probability mass function (PMF): probability distribution  of a discrete random variable, provides the \n",
    "# possible values and their associated probabilities. A probability mass function differs from a PDF \n",
    "# in that the latter is associated with continuous rather than discrete random variables. A PDF must be integrated \n",
    "# over an interval to yield a probability.\n",
    "axes[0].plot(n, Y.pmf(n), 'o')\n",
    "\n",
    "# plot the cumulative distribution function (CDF)\n",
    "axes[1].step(n, Y.cdf(n))\n",
    "\n",
    "# plot histogram of 1000 random realizations of the stochastic variable X\n",
    "axes[2].hist(Y.rvs(size=200), bins=np.arange(13) - 0.5, density=True, lw=2, edgecolor='w');\n",
    "axes[2].set_xticks(n);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objects support easy access to some of its statistical properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:16.774756Z",
     "start_time": "2019-04-10T13:18:16.751648Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Acces some convenient attributes caracterizing the distribution\n",
    "print(X.mean(), X.std(), X.var()) # normal distribution\n",
    "print(Y.mean(), Y.std(), Y.var()) # poission distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization (finding minima or maxima of a function) is a large field in mathematics, and optimization of complicated functions or in many variables can be rather complicated. Here we will only look at a few very simple cases. For a more detailed introduction to optimization with SciPy see: http://scipy-lectures.github.com/advanced/mathematical_optimization/index.html\n",
    "\n",
    "To use the optimization module in scipy first include the `optimize` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:17.719596Z",
     "start_time": "2019-04-10T13:18:17.669852Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Minimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first look at how to find the minima of a simple function of a single variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:18.385739Z",
     "start_time": "2019-04-10T13:18:17.752548Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 4.5*x**3 + (x-4)**2 + 0.75*x**4 - 20\n",
    "\n",
    "x = np.linspace(-6, 3, 100)\n",
    "plt.plot(x, f(x));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `minimize_scalar` function to find the minima of a scalar function. It provides wrapper around many optimization algorithms you can choose from using the `method` keyword. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:19.206180Z",
     "start_time": "2019-04-10T13:18:18.400048Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result = optimize.minimize_scalar(f)\n",
    "\n",
    "plt.plot(x, f(x));\n",
    "plt.axvline(result.x, color='xkcd:orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add some boundaries\n",
    "result = optimize.minimize_scalar(f, bracket=[-6, -2])\n",
    "plt.plot(x, f(x));\n",
    "plt.axvline(result.x, color='xkcd:dark red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(result))\n",
    "print(f\"Number of evaluation needed to find the minimum: {result.nfev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Minimization in More Dimensions.\n",
    "\n",
    "Below you'll find the infamous *Rosenbrock* function in two dimensions. It's very popular for benchmarking global optimization problems. Its solutions are well known and easily parametrized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:22.808109Z",
     "start_time": "2019-04-10T13:18:20.161476Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def rosenbrock_2d(x, y, a=1, b=1):\n",
    "    return (a - x)**2 + b*(y - x**2)**2\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "\n",
    "x, y = np.meshgrid(np.linspace(-2 ,2, 100), np.linspace(-3. ,5, 100))\n",
    "ax.plot_surface(x, y, rosenbrock_2d(x, y), cmap='magma_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:25.334212Z",
     "start_time": "2019-04-10T13:18:22.853181Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We now use the minimise function starting at the values 5 and 2.\n",
    "result = optimize.minimize(lambda x: rosenbrock_2d(x[0], x[1]), x0=[5, 2])\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "ax.view_init(20, 30)\n",
    "\n",
    "\n",
    "x, y = np.meshgrid(\n",
    "    np.linspace(-2 ,2, 100),\n",
    "    np.linspace(-3. ,5, 100)\n",
    ")\n",
    "\n",
    "ax.plot_surface(x, y, rosenbrock_2d(x, y), cmap='magma_r', alpha=0.6)\n",
    "\n",
    "x, y, z = result.x[0], result.x[1], 20\n",
    "ax.quiver(x, y, z, 0, 0, -1, length=20, arrow_length_ratio=0.04)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Least Squares Minimization\n",
    "\n",
    "The following apply for a sample of N independant observations ($\\mathbf{xi}$, yi) where xi is described by $\\mathbf{p}$ variables and yi is the measurement we seek to explain. We will do that by searching the best linear combination of the xi explaining yi. \n",
    "\n",
    "$$\n",
    "f(x)= \\hat{y} =  \\hat{\\beta}_0 + \\sum_{j=1}^p x_j \\hat{\\beta}_j\n",
    "$$\n",
    "where $f:\\mathbb{R}^{p} \\to \\mathbb{R}$.\n",
    "\n",
    "\n",
    "When we include a 1 as the first entry into our sample $x$ e.g. $x = (1, x_1, x_2, \\ldots, x_p)^T$ we can rewrite\n",
    "$f$ in matrix form\n",
    "\n",
    "$$\n",
    "f(x)= \\hat{y} =  x^T \\mathbf{\\beta}\n",
    "$$\n",
    "\n",
    "where $\\beta = (\\beta_0, \\beta_1, \\beta_2, \\ldots, \\beta_p)^T$.\n",
    "\n",
    "\n",
    "\n",
    "How do you find those weights? Like before we choose a loss function and try to opimize it.\n",
    "In this case we choose a loss function called the residual sum of squares (RSS).\n",
    "We calculate it over all samples $x_i$ in a matrix $\\mathbf{X} \\in \\mathbb{R}^{N\\times p}$.\n",
    "\n",
    "$$L(\\beta) = RSS(\\mathbf{\\beta}) = \\sum_{i=1}^N (y_i - x_i^T \\beta)^2 $$\n",
    "\n",
    "Here $x_i$ is a row in $\\mathbf{X}$ (N observations), viewed as a column vector in $\\mathbb{R}^p$ hence the transpose.\n",
    "\n",
    "We can now rewrite the loss function in matrix form:\n",
    "\n",
    "\n",
    "$$\n",
    "RSS(\\beta) = (\\mathbf{y} - \\mathbf{X} \\beta)^T (\\mathbf{y} - \\mathbf{X} \\beta )\n",
    "$$\n",
    "\n",
    "Now we optimize the loss function just like we would any other function, by differentiating with respect to $\\beta$ and setting the result equals to zero.\n",
    "\n",
    "$$\n",
    " \\mathbf{X}^T (\\mathbf{y} - \\mathbf{X} \\beta ) \\stackrel{!}{=} 0\n",
    "$$\n",
    "\n",
    "Solving for $\\beta$ leads to\n",
    "\n",
    "$$\n",
    "\\hat{\\beta} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}\n",
    "$$\n",
    "\n",
    "\n",
    "We just performed  __Linear Least Squares__ regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toy example: linear regression in dimension 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear model to wich we will add some noise to simulate the data yi.\n",
    "def f(x, beta=[2, 4.5]):\n",
    "    return beta[0] + beta[1]*x\n",
    "\n",
    "x = np.linspace(-6, 3, 100)\n",
    "# Add some normal noise to the model. These are our observations yi that we seek to explain by the linear \n",
    "# combination of the xi\n",
    "y = f(x) + rng.normal(0, 15, size=x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The polynomial model to which we add some noise to simulate the observations yi is a linear combination of $x^0$ and $x^1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the answer matrix, N=100 and p=1\n",
    "X = np.vstack([np.ones(len(x)), x]).T\n",
    "\n",
    "# find the linear least squares solution for the parameters\n",
    "result = optimize.lsq_linear(X, y)\n",
    "\n",
    "plt.plot(x, y, '.')\n",
    "plt.plot(x, f(x), color='gray', label='truth')\n",
    "plt.plot(x, f(x, beta=result.x), color='crimson', label='fit')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's fit some noisy polynomial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:26.303140Z",
     "start_time": "2019-04-10T13:18:25.358931Z"
    }
   },
   "outputs": [],
   "source": [
    "# Polynomial model to wich we will add some noise to simulate the data yi.\n",
    "def f(x, beta=[4.5, 1, 0.75]):\n",
    "    return beta[0]*x**3 + beta[1]*(x-4)**2 + beta[2]*x**4\n",
    "\n",
    "x = np.linspace(-6, 3, 100)\n",
    "# Add some normal noise.\n",
    "y = f(x) + rng.normal(0, 35, size=x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The polynomial model to which we add some noise to simulate the observations yi is a linear combination of x, $(x-4)^2$ and $x^4$ (imagine x is a temperature or Pression). As the modelisator, we are free to choose the variables to explain y. Consisering the notation we took previously, p is going from 1 to 3, and\n",
    "$x_1=x$, $x_2=(x-4)^2$ and $x_3=(x)^4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the answer matrix, N=100 and p=3\n",
    "X = np.vstack([x ** 3, (x - 4) ** 2, x ** 4]).T\n",
    "\n",
    "# find the linear least squares solution for the parameters\n",
    "result = optimize.lsq_linear(X, y)\n",
    "\n",
    "plt.plot(x, y, '.')\n",
    "plt.plot(x, f(x), color='gray', label='truth')\n",
    "plt.plot(x, f(x, beta=result.x), color='crimson', label='fit')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Curve Fitting\n",
    "\n",
    "For more general cases where the parameters are not linear there is the more convenient function `curve_fit`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:27.196526Z",
     "start_time": "2019-04-10T13:18:26.324172Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def f(x, scale=5, loc=4, ):\n",
    "    return (1/(scale))**2*x**3 + (1/(2*loc))*x**2\n",
    "\n",
    "x = np.linspace(-3,  1.5, 100)\n",
    "data = f(x) + rng.normal(0, 0.15, size=x.shape)\n",
    "\n",
    "popt, pcov = optimize.curve_fit(f, x, data, p0=[5, 4, ])\n",
    "\n",
    "plt.plot(x, data, '.')\n",
    "plt.plot(x, f(x), color='gray', label='truth')\n",
    "plt.plot(x, f(x, *popt), color='crimson', label='fit')\n",
    "\n",
    "#Covariance : 2D error\n",
    "print(pcov)\n",
    "# Estimate on the error of the best fit parameter\n",
    "print(np.sqrt(np.diag(pcov)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 Exercise:  Curve Fitting\n",
    "\n",
    "Use `numpy.loadtxt` to load the file called `munich_temperatures_average.txt` and fit a model to it using `optimize.curve_fit`.\n",
    "\n",
    "tips: Let's use the following periodic function to model the data:\n",
    "\n",
    "$ f(temperature,a ,b,c) = a\\times \\cos(2\\times \\pi \\times temperature +b) + c$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:28.454169Z",
     "start_time": "2019-04-10T13:18:27.211173Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load solutions/solution_6.py\n",
    "# flake8: noqa\n",
    "date, temperature = np.loadtxt('./data/munich_temperatures_average.txt', unpack=True)\n",
    "plt.plot(date, temperature, '.')\n",
    "plt.ylim([-20, 30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6 Root Finding\n",
    "\n",
    "To find the solution for a function of the form $f(x) = 0$ we can use the `fsolve` or the `root` function. It requires one or more initial guesses: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 4.5 * x **3 + (x - 4) ** 2 + 0.75 * x ** 4 - 20\n",
    "\n",
    "x = np.linspace(-6, 3, 100)\n",
    "\n",
    "plt.plot(x, f(x))\n",
    "plt.axhline(color='black')\n",
    "\n",
    "result = optimize.root(f, [-6, -3, 0, 2])\n",
    "\n",
    "for r in result.x:\n",
    "    plt.axvline(r, color='xkcd:tangerine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolation is simple and convenient in scipy: The `interp1d` function, when given arrays describing X and Y data, returns and object that behaves like a function that can be called for an arbitrary value of x (in the range covered by X), and it returns the corresponding interpolated y value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:28.552573Z",
     "start_time": "2019-04-10T13:18:28.479360Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "\n",
    "def f(x):\n",
    "    return np.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:28.639669Z",
     "start_time": "2019-04-10T13:18:28.564358Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = [0, 1, 2, 3, 3.5, 4, 6, 6.5, 7, 9]\n",
    "x = np.linspace(0, 9, 100)\n",
    "\n",
    "y_measured = f(n) \n",
    "\n",
    "linear_interpolation = interpolate.interp1d(n, y_measured)\n",
    "\n",
    "cubic_interpolation = interpolate.interp1d(n, y_measured, kind='cubic')\n",
    "# this returns a new function we can call for values of x\n",
    "cubic_interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:29.692238Z",
     "start_time": "2019-04-10T13:18:28.661870Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(n, y_measured, 's', label='noisy data', color='black')\n",
    "plt.plot(x, f(x), c='gray', lw=2, label='true function')\n",
    "plt.plot(x, linear_interpolation(x), label='linear interpolation')\n",
    "plt.plot(x, cubic_interpolation(x), label='cubic interpolation')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Side comments:\n",
    "There are also methods for higher interpolation, 2D or 3D data. One very useful module is the\n",
    "[RegularGridInterpolator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.RegularGridInterpolator.html).\n",
    "[Spline interpolation](https://docs.scipy.org/doc/scipy/tutorial/interpolate.html#spline-interpolation) may also answer your needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. SciPy IO Module\n",
    "\n",
    "## 9.1 Wave files\n",
    "\n",
    "SciPy provides some useful methods for reading file from MatLab, NetCDF or WAV data. Below is an example which uses the `scipy.io.wavfile` module to write a file containing the sound of hydrogen atoms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:31.393304Z",
     "start_time": "2019-04-10T13:18:29.734027Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "\n",
    "#standard rate for this king of Audio File.\n",
    "rate = 44100 #44.1 khz\n",
    "duration = 10 # in sec\n",
    "\n",
    "# We define an audio signal here from the lyman and balmer series of a hydrogen atom (n defines the frequencies and\n",
    "# m the harmonics.\n",
    "def rydberg(n, m):\n",
    "    return (1 / (n ** 2) - 1 / (m ** 2)) \n",
    "\n",
    "def lyman(m):\n",
    "    \"\"\"Lyman series\"\"\"\n",
    "    return rydberg(1, m)\n",
    "\n",
    "def balmer(m):\n",
    "    \"\"\"Balmer series\"\"\"\n",
    "    return rydberg(2, m)\n",
    "\n",
    "#sound signal generated with a sinus function with the frequency given by the Lyman or balmer series \n",
    "def sound(frequency, time):\n",
    "    return 2 ** 12 * np.sin(2 * np.pi * 440 * frequency * time)\n",
    "\n",
    "# time sample defined by the duraction here 10 sec and a rate.\n",
    "t = np.linspace(0, duration, rate * duration)\n",
    "hydrogen_sound = np.sum(\n",
    "    [sound(lyman(i), t) + sound(balmer(i), t) for i in range(2, 12)], axis=0) / 6\n",
    "\n",
    "plt.plot(t[:10000], hydrogen_sound[:10000])\n",
    "\n",
    "#write it to standar audio file with wavfile.write\n",
    "wavfile.write('data/hydrogen.wav', rate, hydrogen_sound.astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:31.407283Z",
     "start_time": "2019-04-10T13:18:31.396924Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<audio controls=\"controls\" style=\"width:600px\" >\n",
    "  <source src=\"data/hydrogen.wav\" type=\"audio/wav\" />\n",
    "</audio>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Exercise:  Signal Processing and IO.\n",
    "\n",
    "Load the file `synth_sound.wav` and plot a the frequency spectrum vs time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:18:31.416879Z",
     "start_time": "2019-04-10T13:18:31.411014Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load solutions/solution_4.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
