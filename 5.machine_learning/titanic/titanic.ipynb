{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc18a407-8394-4ca4-bb0a-9ae0da2377e5",
   "metadata": {},
   "source": [
    "# Machine Learning introduction course\n",
    "\n",
    "Freely derived from https://www.kaggle.com/c/titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ec616d-d643-482d-a385-efa2682521a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526adbf9-d5dc-46ec-8847-f9df806fcbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upgrade seborn to solve issue with annotation in correlation matrix\n",
    "# !pip install seaborn --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c13b316-8ffd-4b3a-b7e9-759ece62726c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read the data\n",
    "\n",
    "You should know how to that now... hint: üêº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e50ad8-0043-486c-b993-2d21a59ad6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904e8621-1973-4d7a-bfc8-1969df2f9067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "489ff27a-dba5-4589-ac24-3345ef32fdbc",
   "metadata": {},
   "source": [
    "## Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2736f15a-87c2-4f52-8713-1895d4f3e56b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3eacce-ce2a-4f71-844b-8c1c6a27e37e",
   "metadata": {},
   "source": [
    "#### Columns in the dataset\n",
    "\n",
    "0. **pclass**: Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd). Proxy for socio-economic status.\n",
    "\n",
    "1. **survived**: Survival (0 = No; 1 = Yes).\n",
    "\n",
    "2. **name**: Name of the passenger.\n",
    "\n",
    "3. **sex**: Sex of the passenger.\n",
    "\n",
    "4. **age**: Age of the passenger.\n",
    "\n",
    "5. **sibsp**: Number of Siblings/Spouses Aboard.\n",
    "\n",
    "6. **parch**: Number of Parents/Children Aboard.\n",
    "\n",
    "7. **ticket**: Ticket Number.\n",
    "\n",
    "8. **fare**: Passenger Fare.\n",
    "\n",
    "9. **cabin**: Cabin number.\n",
    "\n",
    "10. **embarked**: Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton).\n",
    "\n",
    "11. **boat**: Lifeboat (if the passenger survived and was on a lifeboat).\n",
    "\n",
    "12. **body**: Body identification number (if the passenger did not survive and their body was found).\n",
    "\n",
    "13. **home.dest**: Home/Destination of the passenger.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4fe060-31c0-4ea4-963a-dc6e0a1d456d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ecd5d4-c8ff-434f-86e8-250645ade14a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af71b58f-b836-43ac-b489-8caf9df2a4b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic.hist(figsize=(15,10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5aa147-4bc5-4695-8b47-25529a484973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c465fb4f-2360-4735-81c0-fc82cc8a7f26",
   "metadata": {},
   "source": [
    "## Find some correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b913001f-0855-473c-b17d-12ea3ff9d2c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c20b6c-b77d-4d38-bc3a-03773cf161ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "df_numeric = titanic.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "corr_matrix = df_numeric.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f084f8e-5e21-4732-8a13-509a6caaaac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "578c270e-4a63-46fc-ba55-8adb65e20c31",
   "metadata": {},
   "source": [
    "### Exercise: Find another one by encoding the `sex` column into integer and rerun the correlation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7081412d-97ea-482e-b9dc-83481170816b",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb9ff60-a9e8-4987-ac8f-46b50ec78e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['sex']=='male'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0ca4d5-fce7-44e8-ad96-4c7dde61383d",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['male'] = (titanic['sex']=='male').astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81281e80-fb1d-4a9c-a04d-2a079fb0513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb526931-f93e-40c5-bee0-c19da44d888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "df_numeric = titanic.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "corr_matrix = df_numeric.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844c3678-38c6-4246-9276-ee851414961a",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d0eb87-dfd0-4cd4-b6ba-97a1f9f62b9f",
   "metadata": {},
   "source": [
    "Here we will try to predict the probability to survive of unkown persons.    \n",
    "The target variable will then be `survived` and we must drop the `body` variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38324a19-2e2c-481e-97e5-63caddde8efa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = 'survived'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca948e66-10b5-4d1e-9a0f-d45a3ed69e14",
   "metadata": {},
   "source": [
    "### Choose your training features as a list of strings from the colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd75a1f4-4ed5-4f29-8177-ef6968186762",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_features = ['age', 'fare', 'pclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91d0bcc-988f-4312-a365-3773250567ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we will work with this data for now\n",
    "\n",
    "data = titanic[training_features + [target]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515e50a3-23ae-4aab-9eb2-01874b8b6df5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b58cb469-82a7-4d4e-9a66-266328d1928c",
   "metadata": {},
   "source": [
    "### Fixing the random seed for reproducibility of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d2eb78-b2f0-43e9-86ac-a7864af4953a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820020e4-dac6-4dff-bc68-35a32ac46501",
   "metadata": {},
   "source": [
    "## Divide the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b33285-ffff-46a8-8df4-28b674497596",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lets drop all NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8f785c-fbbb-4c85-a052-f04eabeb4617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bd19ab-3406-4335-af29-f1dfa5461330",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# X will be the input, so we drop the target feature. y is the output = target.\n",
    "X = data.drop(target, axis=1)[training_features]  \n",
    "y = data[target]  \n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbe4935-5c8f-4f13-8ed5-d0bf2622b557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a027e786-3652-4b38-954c-8d11114e69d8",
   "metadata": {},
   "source": [
    "## Train your first classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee7e57b-0dc6-42d3-9345-d6b1c70c351a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eff3578-d6ff-4d6a-b5f2-70e26b4b6d76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da87f351-fd82-4cf5-96a1-7c59623f846f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = classifier.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2a5d48-77e2-40f3-8e3e-5e8c0c1881ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(np.transpose([y_test.values, pred]), columns=['truth', 'prediction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d47fec9-cf10-4b53-8bc2-c4930e9cbf64",
   "metadata": {},
   "source": [
    "Is this good ? ... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d0ae66-af74-4fc5-943b-182c7b6889e7",
   "metadata": {},
   "source": [
    "## Evaluation of the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6c1613-d721-4420-bf20-de8767d28ea7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Classification Metrics in Machine Learning\n",
    "\n",
    "#### True / False - Positives / Negatives\n",
    "\n",
    "![true_pos](https://miro.medium.com/v2/resize:fit:640/format:webp/1*7EYylA6XlXSGBCF77j_rOA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13939df8-cd1e-4c09-9dbb-c80b2bbf380e",
   "metadata": {},
   "source": [
    "When we build a classification model, it's important to assess its performance. This is done using various metrics that each provide different insights into the quality of the model. Here are some of the main classification metrics:\n",
    "\n",
    "#### 1. Accuracy\n",
    "\n",
    "Accuracy is the most intuitive performance measure. It is simply a ratio of correctly predicted observations to the total observations.\n",
    "\n",
    "$$ \\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}} = \\frac{\\text{True negatives + True positives}}{\\text{Total Number of Predictions}} $$\n",
    "\n",
    "**Advantages:**\n",
    "- Easy to understand and interpret.\n",
    "- Useful when the target classes are well balanced.\n",
    "\n",
    "**Drawbacks:**\n",
    "- Can be misleading if the data is imbalanced. A model that always predicts the majority class will have high accuracy but may be a poor model.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/Sensitivity_and_specificity_1.01.svg/341px-Sensitivity_and_specificity_1.01.svg.png\" alt=\"Sensitivity and Specificity\" width=\"341\" align='right'>\n",
    "\n",
    "#### 2. Precision (Specificity)\n",
    "\n",
    "Precision is the ratio of correctly predicted positive observations to the total predicted positives. High precision relates to the low false positive rate.\n",
    "\n",
    "$$ \\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}} $$\n",
    "\n",
    "\n",
    "**Advantages:**\n",
    "- Useful when the cost of False Positives is high. For example, in spam detection, you would rather let a few spam emails through (False Negatives) than accidentally mark a legitimate email as spam (False Positive).\n",
    "\n",
    "**Drawbacks:**\n",
    "- Not useful if the cost of False Negatives is high. It doesn't take into account the False Negatives.\n",
    "\n",
    "\n",
    "source: https://en.wikipedia.org/wiki/File:Sensitivity_and_specificity_1.01.svg\n",
    "\n",
    "#### 3. Recall (Sensitivity)\n",
    "\n",
    "Recall (also known as sensitivity or true positive rate) is the ratio of correctly predicted positive observations to the all observations in actual class.\n",
    "\n",
    "$$ \\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}} $$\n",
    "\n",
    "**Advantages:**\n",
    "- Useful when the cost of False Negatives is high. For example, in disease prediction, you would rather predict that a healthy person is sick (False Positive) than overlook a sick person (False Negative).\n",
    "\n",
    "**Drawbacks:**\n",
    "- Not useful if the cost of False Positives is high. It doesn't take into account the False Positives.\n",
    "\n",
    "\n",
    "#### 4. F1 Score\n",
    "\n",
    "The F1 Score is the weighted average of Precision and Recall. It tries to find the balance between precision and recall. It is useful in the case of uneven class distribution problems.\n",
    "\n",
    "$$ \\text{F1 Score} = 2*\\frac{\\text{Precision}*\\text{Recall}}{\\text{Precision} + \\text{Recall}} $$\n",
    "\n",
    "**Advantages:**\n",
    "- Balances the trade-off between Precision and Recall.\n",
    "- Useful when the data is imbalanced.\n",
    "\n",
    "**Drawbacks:**\n",
    "- Not interpretable in terms of the business problem.\n",
    "- Assumes that Precision and Recall are equally important, which might not be the case.\n",
    "\n",
    "\n",
    "#### 5. Area Under ROC (Receiver Operating Characteristic) Curve (AUC-ROC)\n",
    "\n",
    "AUC-ROC curve is a performance measurement for classification problem at various thresholds settings. ROC is a probability curve and AUC represents the degree or measure of separability. It tells how much th emodel is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s and 1s as 1s.\n",
    "\n",
    "Each of these metrics provides a different perspective on the performance of the model, and it's important to consider all of them when evaluating your model. The choice of metric depends on your scientific objective.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/13/Roc_curve.svg/1024px-Roc_curve.svg.png\" alt=\"Sensitivity and Specificity\" width=\"500\" >\n",
    "\n",
    "**Advantages:**\n",
    "- Useful for binary classification problems.\n",
    "- Takes into account both False Positive rate (1-Specificity) and True Positive rate (Recall).\n",
    "\n",
    "**Drawbacks:**\n",
    "- Not suitable for imbalanced datasets: can be overly optimistic if classes are highly imbalanced.\n",
    "- More difficult to interpret in terms of scientific"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cbbd88-fc88-46df-b237-7ddf3ff05c67",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1e25a41-1c2c-4292-a6c1-ab5246ab02a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "---- \n",
    "Consider the case of a population of 1000 patients: 990 of the patients are healthy and 10 have a disease.  \n",
    "\n",
    "We build a test that returns the following results:\n",
    "- Patients with disease (predicted) = 0 (our model predicts everyone as healthy)\n",
    "- Healthy patients (predicted) = 1000 (our model predicts everyone as healthy)\n",
    "\n",
    "Give TP, TN, FP, FN.\n",
    "\n",
    "What is the accuracy? Is this a good measure of our test performances?\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f655c09-b26e-415e-bfa8-f28fe33a9846",
   "metadata": {},
   "source": [
    "TP = 990\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 10\n",
    "\n",
    "accuracy = 990 / 1000 = 99%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4ec4c7-a322-4dfc-910d-057a3d01a565",
   "metadata": {},
   "source": [
    "\n",
    "Now let's compute these metrics for our dataset.    \n",
    "Is the test dataset balanced ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4cf480-e27e-4f5b-b9ad-c0d45d1ca901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401f5c90-e534-4059-9233-e2abbea89251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "## cm = cm/cm.sum()  # if you prefer %\n",
    "\n",
    "sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034f55cb-1fda-4692-a7a9-d181228ff423",
   "metadata": {},
   "source": [
    "### Question: where are the true positives, true negatives, false positives and false negatives ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29e4731-221e-4115-aeed-0c986997eb0d",
   "metadata": {},
   "source": [
    "true positives = 39\n",
    "TN = 90\n",
    "FP = 50\n",
    "FN = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df92851-237b-42c8-9050-3618aea36bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a4258c-34e9-4d9f-ac03-90faa53d421a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "\n",
    "print(f\"The accuracy of the prediction is: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb6b2f6-c8d0-4e4f-8af0-b730268de643",
   "metadata": {},
   "source": [
    "### Exercise: compute the precision, recall and f1_score. \n",
    "Be mindful of the `pos_label`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80724302-4084-4f2a-acca-3f147c4975d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92657fd-21a5-4e41-8c2c-6568134de6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_test, pred, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd767f4b-be21-4223-947a-4e7fdeec1d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test, pred, pos_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b625ed0-7c62-4a5d-87b8-9a5f77edfaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, pred, pos_label=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a018bf-3985-455c-8547-5401a9a7a5b2",
   "metadata": {},
   "source": [
    "### Prediction of the probability \n",
    "\n",
    "Instead of predicting directly the class, the classifier is providing a probability for each sample and class and then applies a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb191a94-aff4-492d-ae98-4ebab2f43839",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_proba = classifier.predict_proba(X_test)\n",
    "pred_proba[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b456dbe-d2f2-4f96-aae0-6ae3c0247157",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ROC Curve and AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9603b5-cbb5-4e05-9964-8ef79536d12f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, pred_proba[:,1])\n",
    "roc_auc = roc_auc_score(y_test, pred_proba[:,1])\n",
    "\n",
    "plt.plot(fpr, tpr, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c56ceb-b206-4558-b098-a4aa9cbc2b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70785a08-b981-48e8-9144-76871aff4342",
   "metadata": {},
   "source": [
    "# Improving the performances\n",
    "\n",
    "We have now trained our first classifier, but let's try to improve its performances.\n",
    "There are many ways we can try to improve it, here we'll see:\n",
    "- trying different algorithms\n",
    "- playing with hyperparameters\n",
    "- feature engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee98a37f-943c-4acf-b1ef-417a85fba3d7",
   "metadata": {},
   "source": [
    "**_Metric ?_**    \n",
    "Let's say our goal is to maximise survival (= disease like problem), so we will try to **maximise recall with a positive label = 0**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d4a972-eab9-41d8-af74-06fe662ed521",
   "metadata": {},
   "source": [
    "## Trying different algorithms\n",
    "\n",
    "![](https://scikit-learn.org/stable/_static/ml_map.png)\n",
    "source: https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7645a4d-2d75-48e4-9d94-f1c4662ba717",
   "metadata": {},
   "source": [
    "### Exercise: Model and hyperparameters\n",
    "\n",
    "Try the prediction with a GradientBoostingClassifier\n",
    "\n",
    "Then play with the hyperparameters to try to improve the performances.\n",
    "\n",
    "Note down the best recall along with the hyperparameters used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb6d59d-3a6e-4fad-860f-81aac4fe263e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0a5a34-98af-470e-b24c-a7e4bd3a0d1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier_2 = GradientBoostingClassifier()\n",
    "\n",
    "# train new classifier:\n",
    "classifier_2.fit(X_train, y_train)\n",
    "\n",
    "# make new predcition:\n",
    "pred = classifier_2.predict(X_test)\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e529fb-3d83-42fb-8d85-163f3b3dcbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651c27f8-6be2-4a16-a4c1-c0a6a91bbc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test, pred, pos_label=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965a09b6-249d-4c35-8998-067d7e25ed0e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question: what are the issues with this way of doing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4386c4-b3d0-41d9-9c28-5a2f8f62e5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3aaf8f-a845-4fb0-a6f5-84d3fb37e675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5c29076-3047-41a2-8e46-8195aea78978",
   "metadata": {},
   "source": [
    "### A word on overfitting\n",
    "\n",
    "#### Why increasing the number of estimators is not always a good thing ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e090bb8b-1f8a-4520-b2c2-360066ee32d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_estimators = [10, 20, 50, 100, 400, 1000]\n",
    "\n",
    "recall = []\n",
    "recall_train = []\n",
    "\n",
    "for n in n_estimators:\n",
    "    classifier = GradientBoostingClassifier(n_estimators=n)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    pred = classifier.predict(X_test)\n",
    "    pred_train = classifier.predict(X_train)\n",
    "    \n",
    "    recall.append(recall_score(y_test, pred, pos_label=0))\n",
    "    recall_train.append(recall_score(y_train, pred_train, pos_label=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e7d9b5-c7f8-4aa4-953b-ff3a23ffc2f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(n_estimators, recall, label='test recall')\n",
    "plt.plot(n_estimators, recall_train, label='train recall')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('score')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a526ae7f-ed42-440a-9fb3-dcbb76983453",
   "metadata": {},
   "source": [
    "#### Why optimising (even by hand!) to find the best score on the test dataset is not a good practice either?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73962862-1bdd-43dd-b755-fa511bf16888",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_estimators = [5, 10, 20]\n",
    "learning_rate = [0.01, 0.1, 1]\n",
    "max_depth = [1, 3, 5]\n",
    "\n",
    "best_params = None\n",
    "highest_recall = 0\n",
    "\n",
    "for n in n_estimators:\n",
    "    for lr in learning_rate:\n",
    "        for md in max_depth:\n",
    "            gbc = GradientBoostingClassifier(n_estimators=n, learning_rate=lr, max_depth=md)\n",
    "            gbc.fit(X_train, y_train)\n",
    "            preds = gbc.predict(X_test)\n",
    "            recall = recall_score(y_test, preds, pos_label=0)\n",
    "            if recall > highest_recall:\n",
    "                highest_recall = recall\n",
    "                best_params = {'n_estimators': n, 'learning_rate': lr, 'max_depth': md}\n",
    "\n",
    "print(\"Best parameters: \", best_params)\n",
    "print(\"Highest recall on test set: \", highest_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb92ef8-89af-4d1b-974b-897185909d37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd31596e-5932-431f-83f0-e067dfdd51b7",
   "metadata": {},
   "source": [
    "### Validation dataset\n",
    "\n",
    "To avoid the issue of information leak from the test dataset into the model, we use a validation dataset taken from the training dataset.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*Nv2NNALuokZEcV6hYEHdGA.png\" alt=\"Sensitivity and Specificity\" width=\"600\" align=\"center\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6df9e5-eb16-4a8c-a089-cde74c85820a",
   "metadata": {},
   "source": [
    "#### Cross-validation\n",
    "\n",
    "> However, by partitioning the available data into three sets, we drastically reduce the number of samples which can be used for learning the model, and the results can depend on a particular random choice for the pair of (train, validation) sets.\n",
    "\n",
    "> A solution to this problem is a procedure called cross-validation (CV for short). A test set should still be held out for final evaluation, but the validation set is no longer needed when doing CV. In the basic approach, called k-fold CV, the training set is split into k smaller sets (other approaches are described below, but generally follow the same principles). The following procedure is followed for each of the k ‚Äúfolds‚Äù:\n",
    "A model is trained using `k-1` of the folds as training data;\n",
    "the resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy).\n",
    "The performance measure reported by k-fold cross-validation is then the average of the values computed in the loop. This approach can be computationally expensive, but does not waste too much data (as is the case when fixing an arbitrary validation set), which is a major advantage in problems such as inverse inference where the number of samples is very small.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" alt=\"Sensitivity and Specificity\" width=\"800\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "source: https://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339190fb-8459-4112-9d7d-103e3b08fa8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, recall_score\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'max_depth': [1, 3, 5]\n",
    "}\n",
    "\n",
    "classifier = GradientBoostingClassifier()\n",
    "\n",
    "scorer = make_scorer(recall_score, pos_label=0)\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = param_grid,\n",
    "                           scoring=scorer,\n",
    "                           cv = 5)\n",
    "\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "print(\"Best score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfc009f-be74-42e3-a1a7-07abe70c6a40",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2da417-8342-40cc-bfad-d1acebc8e6ae",
   "metadata": {},
   "source": [
    "### Visualize features importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafcb7b1-5c6c-4044-b8b6-7cd7cf43bec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Get feature importances\n",
    "importances = classifier.feature_importances_\n",
    "\n",
    "feature_names = training_features\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "# Rearrange feature names so they match the sorted feature importances\n",
    "names = [feature_names[i] for i in indices]\n",
    "\n",
    "plt.figure(figsize=(9,4))\n",
    "plt.barh(range(len(indices)), importances[indices])\n",
    "\n",
    "plt.yticks(range(len(indices)), names, rotation=0);\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ee7cd8-ee53-42df-bace-d09436107abc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# Work on a copy of the dataset in case you perform destructive operations\n",
    "df = deepcopy(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ea949d-720a-48ee-927d-8c6497baf872",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccddde2f-0a0a-4155-8414-94f1326f1dfe",
   "metadata": {},
   "source": [
    "### Filling missing values\n",
    "One can fill missing values in order to increase the size of training data.\n",
    "There are many strategies to fill the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd71f02b-7240-4023-80b9-50f6ec1549fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example with the port: fill missing embarked values with the most common port\n",
    "df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297ff728-25c6-4b78-9b3c-220881db3fcd",
   "metadata": {},
   "source": [
    "#### Exercice: Proceed with other columns with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dc4b6e-6439-419f-82e2-fc04f8d2fee7",
   "metadata": {},
   "source": [
    "### Create new features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd798c1-21c3-42db-9c1c-a860b03eec47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example: extract title from Name\n",
    "df['Title'] = df['name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ceb5f9-71eb-41c2-b2b4-5db835a6d01b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Exercice: create a `family_size` column by combining `sibsp` and `parch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5306d9cb-623d-4cce-a257-2335e3bf84e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c513c59f-1a85-4aea-b7ee-55f0c1597f95",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Exercice: Bin `age` into different age groups to create a column `age_group`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e502fa41-637f-495e-a5d3-a4b79f68b3d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7decdbfb-17e5-4a32-b9dd-ba6d6a8650fc",
   "metadata": {},
   "source": [
    "### Scale the features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d47166-4a00-4e71-a04d-5dcc8a2bf38e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the 'Age' and 'Fare' columns and transform them\n",
    "df[['age', 'fare']] = scaler.fit_transform(df[['age', 'fare']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8db28a-64c5-4786-a197-78163827d879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a651166-b929-4f5c-ad52-45d0dbd74453",
   "metadata": {},
   "source": [
    "### Encode features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474aac79-cd64-4ec9-bd35-5e700e247f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['sex'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6061071-bb9c-447a-8540-f90d3254fe8e",
   "metadata": {},
   "source": [
    "####  Q: Another column we can apply this to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25152701-eb0b-4ff5-ac16-2ca40e74f70e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ae6ca1-8850-45fd-b3f0-0b4f9b0792f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finally, drop features that might not be useful\n",
    "df = df.drop(['name', 'ticket', 'cabin', 'body', 'home.dest', 'boat'], axis=1)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbc9eed-e116-4bc9-8915-790ed60cfb18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df39f3b2-a8b2-429a-9b4d-37aeb5a2d710",
   "metadata": {},
   "source": [
    "## Train a new classifier with this data\n",
    "- try different hyperparameters (use GridCV)\n",
    "- who got the best classifier ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5503a0a0-f5e9-41e0-885e-455e3f169138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d25ebb-a012-41aa-b874-94b63f214b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655267af-56d8-4522-a532-ba044b899830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e72d44-665d-4c24-8cc1-dc976ebe73dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e180097-73aa-44c5-ad13-c205897da9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fa4373-c221-48e6-9a2e-78fef73455ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28db29c8-f356-443b-9094-91cf9434f2fb",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ca4bdb-26e1-4147-a3db-a94be7d07c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
